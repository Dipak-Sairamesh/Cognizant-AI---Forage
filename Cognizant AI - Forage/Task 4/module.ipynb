{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16549,"status":"ok","timestamp":1718140627531,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"GUS6AlTWKR9i","outputId":"f648df11-1e44-430e-b7a7-5705de0f276b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":201,"status":"ok","timestamp":1718140679201,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"KvytWQlnH5j2"},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","import joblib"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1718141452146,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"EiIjGp9PH5j4"},"outputs":[],"source":["# Function to load the dataset\n","def load_data(file_path):\n","    \"\"\"\n","    Load the CSV data into a DataFrame.\n","\n","    :param file_path: str, path to the CSV file\n","    :return: DataFrame\n","    \"\"\"\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1718141452938,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"OyzZJAG2H5j4"},"outputs":[],"source":["# Function to split the dataset into training and testing sets\n","def split_data(data, test_size=0.2):\n","    \"\"\"\n","    Split the dataset into training and testing sets.\n","\n","    :param data: DataFrame, the dataset to split\n","    :param test_size: float, proportion of the dataset to include in the test split\n","    :return: tuple, (X_train, X_test, y_train, y_test)\n","    \"\"\"\n","    X = data.drop('estimated_stock_pct', axis=1)\n","    y = data['estimated_stock_pct']\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n","\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1718141454381,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"_4tHrDvBH5j4"},"outputs":[],"source":["# Function to train the model\n","def train_model(X_train, y_train):\n","    \"\"\"\n","    Train a RandomForest model on the training data.\n","\n","    :param X_train: DataFrame, training features\n","    :param y_train: Series, training labels\n","    :return: trained model\n","    \"\"\"\n","    model = RandomForestRegressor(random_state=42)\n","\n","    model.fit(X_train, y_train)\n","\n","    return model"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1718141455903,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"Yok5DPBuH5j5"},"outputs":[],"source":["# Function to evaluate the model\n","def evaluate_model(model, X_test, y_test):\n","    \"\"\"\n","    Evaluate the trained model on the test data.\n","\n","    :param model: trained model\n","    :param X_test: DataFrame, test features\n","    :param y_test: Series, test labels\n","    :return: float, accuracy score\n","    \"\"\"\n","    y_pred = model.predict(X_test)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    return mae"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718141457137,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"zc4RC40DH5j5"},"outputs":[],"source":["# Function to save the trained model\n","def save_model(model, file_path):\n","    \"\"\"\n","    Save the trained model to disk.\n","\n","    :param model: trained model\n","    :param file_path: str, path to save the model\n","    \"\"\"\n","    joblib.dump(model, file_path)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718141458379,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"NqgyxkCfH5j5"},"outputs":[],"source":["# Main function to execute the workflow\n","def main(file_path, model_save_path):\n","    \"\"\"\n","    Execute the machine learning workflow: load data, split, train, evaluate, and save model.\n","\n","    :param file_path: str, path to the CSV file\n","    :param model_save_path: str, path to save the trained model\n","    \"\"\"\n","    # Load the data\n","    data = load_data(file_path)\n","\n","    K = 10\n","    accuracy = []\n","\n","    for i in range(0, K):\n","\n","      # Split the data\n","      X_train, X_test, y_train, y_test = split_data(data)\n","      scaler = StandardScaler()\n","\n","      scaler.fit(X_train)\n","      X_train = scaler.transform(X_train)\n","      X_test = scaler.transform(X_test)\n","\n","      # Train the model\n","      model = train_model(X_train, y_train)\n","\n","      # Evaluate the model\n","      mae = evaluate_model(model, X_test, y_test)\n","      accuracy.append(mae)\n","      print(f\"Model MAE for fold {i+1}: {mae:.3f}%\")\n","\n","    # Print average MAE across all folds\n","    average_mae = sum(accuracy) / len(accuracy)\n","    print(f\"Average MAE: {average_mae:.2f}%\")\n","\n","    # Save the model\n","    save_model(model, model_save_path)\n","    print(f\"Model saved to {model_save_path}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43719,"status":"ok","timestamp":1718141503950,"user":{"displayName":"dipak sairamesh","userId":"01715976198169624120"},"user_tz":420},"id":"jy6tbF1eH5j5","outputId":"315a0cc6-22f1-4498-b75a-fdf3ec84e0ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model MAE for fold 1: 0.234%\n","Model MAE for fold 2: 0.234%\n","Model MAE for fold 3: 0.234%\n","Model MAE for fold 4: 0.234%\n","Model MAE for fold 5: 0.234%\n","Model MAE for fold 6: 0.234%\n","Model MAE for fold 7: 0.234%\n","Model MAE for fold 8: 0.234%\n","Model MAE for fold 9: 0.234%\n","Model MAE for fold 10: 0.234%\n","Average MAE: 0.23%\n","Model saved to /content/drive/MyDrive/Projects/Cognizant AI - Forage/Task 4/model.pkl\n"]}],"source":["# Entry point for the script\n","if __name__ == \"__main__\":\n","    # Example usage\n","    csv_file_path = \"/content/drive/MyDrive/Projects/Cognizant AI - Forage/Task 4/df_merged.csv\"\n","    model_output_path = \"/content/drive/MyDrive/Projects/Cognizant AI - Forage/Task 4/model.pkl\"\n","    main(csv_file_path, model_output_path)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
